"""
Artifact Extraction Utilities

This module provides utilities for extracting, processing, and managing artifacts
generated by workflows that support artifact generation.
"""

from typing import Dict, Any, List, Optional
from super_starter_suite.shared.config_manager import config_manager

logger = config_manager.get_logger("artifact.utils")


def extract_artifact_metadata(artifact_event_data: Any) -> Dict[str, Any]:
    """
    Extract standardized metadata from various artifact event formats.

    Supports different artifact types:
    - CodeArtifactData: has 'code', 'language', 'file_name'
    - DocumentArtifactData: has 'content', 'title', 'type'
    - Generic artifacts: fallback parsing

    Args:
        artifact_event_data: Raw artifact data from workflow events

    Returns:
        Dict containing standardized artifact metadata
    """
    try:
        # Initialize with defaults
        artifact_data = {
            'type': getattr(artifact_event_data, 'type', 'unknown'),
            'language': '',
            'file_name': '',
            'code': '',
            'content': '',  # For document artifacts
            'title': '',     # For document artifacts
            'created_at': getattr(artifact_event_data, 'created_at', None)
        }

        # Handle type enum vs string conversion
        if hasattr(artifact_data['type'], 'value'):
            artifact_data['type'] = artifact_data['type'].value

        # Extract data based on artifact type and structure
        if hasattr(artifact_event_data, 'data'):
            data = artifact_event_data.data

            # Handle DocumentArtifactData (deep_research, document_generator)
            if hasattr(data, 'content'):
                artifact_data['content'] = getattr(data, 'content', '')
                artifact_data['code'] = artifact_data['content']  # Map to code field for compatibility
                artifact_data['title'] = getattr(data, 'title', '')
                artifact_data['language'] = 'markdown'  # Default for documents

                # Generate filename from title or type
                title = artifact_data['title']
                if title:
                    # Clean title for filename
                    clean_title = "".join(c for c in title if c.isalnum() or c in ' -_').strip()
                    artifact_data['file_name'] = f"{clean_title}.md"
                else:
                    artifact_data['file_name'] = f"{artifact_data['type']}_{int(artifact_data['created_at'] or 0)}.md"

                logger.debug(f"Extracted DocumentArtifactData: title='{artifact_data['title'][:50]}...', content_len={len(artifact_data['content'])}")

            # Handle CodeArtifactData or generic code artifacts
            elif hasattr(data, 'code'):
                artifact_data['code'] = getattr(data, 'code', '')
                artifact_data['language'] = getattr(data, 'language', '')
                artifact_data['file_name'] = getattr(data, 'file_name', '')

                # Auto-generate filename if missing
                if not artifact_data['file_name']:
                    lang_ext = artifact_data['language'].lower()
                    ext_map = {'python': 'py', 'javascript': 'js', 'typescript': 'ts', 'html': 'html', 'css': 'css', 'json': 'json'}
                    ext = ext_map.get(lang_ext, 'txt')
                    artifact_data['file_name'] = f"generated_{artifact_data['type']}.{ext}"

                logger.debug(f"Extracted CodeArtifactData: language={artifact_data['language']}, code_len={len(artifact_data['code'])}")

            # Generic fallback for unknown artifact data structures
            else:
                logger.warning(f"Unknown artifact data structure: {type(data)}")
                # Extract any strings we can find
                for attr_name in dir(data):
                    if not attr_name.startswith('_'):
                        attr_value = getattr(data, attr_name, None)
                        if attr_value and isinstance(attr_value, str):
                            if 'code' in attr_name.lower() or 'content' in attr_name.lower():
                                artifact_data['code'] = attr_value
                            elif 'name' in attr_name.lower() or 'file' in attr_name.lower():
                                artifact_data['file_name'] = attr_value
                            elif 'lang' in attr_name.lower():
                                artifact_data['language'] = attr_value

        # Validate that we extracted some content
        has_content = bool(artifact_data.get('code') or artifact_data.get('content'))
        content_len = len(artifact_data.get('code', '') or artifact_data.get('content', ''))

        print(f"DEBUG: Artifact extraction: type={artifact_data['type']}, content_len={content_len}, has_content={has_content}")

        logger.debug(f"Extracted artifact metadata: type={artifact_data['type']}, language={artifact_data.get('language', 'none')}, content_len={content_len}")

        return artifact_data

    except Exception as e:
        logger.error(f"Failed to extract artifact metadata: {e}")
        print(f"ERROR: Artifact extraction failed: {e}")
        # Return minimal artifact data on failure
        return {
            'type': 'error',
            'language': '',
            'file_name': f'error_{id(artifact_event_data)}.txt',
            'code': f'Artifact extraction failed: {str(e)}',
            'content': f'Artifact extraction failed: {str(e)}',
            'created_at': None
        }


def validate_artifacts(artifacts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Validate and clean artifact data.

    Args:
        artifacts: List of artifact dictionaries

    Returns:
        List of validated and cleaned artifacts
    """
    if not artifacts:
        return []

    validated_artifacts = []

    for artifact in artifacts:
        if not isinstance(artifact, dict):
            logger.warning(f"Skipping invalid artifact (not a dict): {type(artifact)}")
            continue

        # Ensure required fields exist
        validated_artifact = {
            'type': artifact.get('type', 'unknown'),
            'language': artifact.get('language', ''),
            'file_name': artifact.get('file_name', ''),
            'code': artifact.get('code', ''),
            'created_at': artifact.get('created_at')
        }

        # Basic validation
        if not validated_artifact['type']:
            validated_artifact['type'] = 'unknown'

        # Ensure code is string
        if validated_artifact['code'] and not isinstance(validated_artifact['code'], str):
            validated_artifact['code'] = str(validated_artifact['code'])

        validated_artifacts.append(validated_artifact)

    logger.debug(f"Validated {len(validated_artifacts)} artifacts out of {len(artifacts)} provided")
    return validated_artifacts


def get_artifact_summary(artifacts: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Generate summary statistics for a set of artifacts.

    Args:
        artifacts: List of artifact dictionaries

    Returns:
        Dict containing artifact summary statistics
    """
    if not artifacts:
        return {
            'total_count': 0,
            'types': [],
            'languages': [],
            'has_code': False,
            'total_code_size': 0
        }

    total_count = len(artifacts)
    types = list(set(art.get('type', 'unknown') for art in artifacts))
    languages = list(set(art.get('language', '') for art in artifacts))
    # Remove empty language strings
    languages = [lang for lang in languages if lang]

    # Code-related statistics
    code_artifacts = [
        art for art in artifacts
        if art.get('code') and art.get('type', '').lower() in ['code', 'script', 'program']
    ]
    total_code_size = sum(len(art.get('code', '')) for art in code_artifacts)

    return {
        'total_count': total_count,
        'types': types,
        'languages': languages,
        'has_code': len(code_artifacts) > 0,
        'total_code_size': total_code_size,
        'code_artifacts_count': len(code_artifacts)
    }


def format_artifacts_for_display(artifacts: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Format artifacts for frontend display with rich UI information.

    Args:
        artifacts: List of artifact dictionaries

    Returns:
        Dict containing formatted artifacts for UI consumption
    """
    if not artifacts:
        return {'artifacts': [], 'summary': get_artifact_summary([])}

    formatted_artifacts = []

    for artifact in artifacts:
        formatted = {
            'id': f"{artifact.get('type', 'unknown')}_{hash(str(artifact))}",
            'type': artifact.get('type', 'unknown'),
            'language': artifact.get('language', ''),
            'file_name': artifact.get('file_name', ''),
            'code': artifact.get('code', ''),
            'created_at': artifact.get('created_at'),
            'has_content': bool(artifact.get('code', '').strip()),
            'content_preview': _get_content_preview(artifact),
            'downloadable': bool(artifact.get('code') and artifact.get('file_name')),
            'syntax_highlight': _get_syntax_highlight_class(artifact),
            'size': len(artifact.get('code', ''))
        }
        formatted_artifacts.append(formatted)

    return {
        'artifacts': formatted_artifacts,
        'summary': get_artifact_summary(artifacts)
    }


def _get_content_preview(artifact: Dict[str, Any]) -> str:
    """Get a preview of artifact content for UI display."""
    code = artifact.get('code', '')
    if not code:
        return ""

    # Take first few lines or first 200 characters
    lines = code.split('\n')[:10]  # First 10 lines
    preview = '\n'.join(lines)

    if len(preview) > 200:
        preview = preview[:200] + "..."

    return preview.strip()


def _get_syntax_highlight_class(artifact: Dict[str, Any]) -> str:
    """
    Get CSS class for syntax highlighting based on artifact type and language.

    This maps to common syntax highlighting libraries like Prism.js or Highlight.js.
    """
    language = artifact.get('language', '').lower()
    art_type = artifact.get('type', '').lower()

    # Direct language mapping
    if language:
        language_map = {
            'python': 'python',
            'java': 'java',
            'javascript': 'javascript',
            'typescript': 'typescript',
            'html': 'html',
            'css': 'css',
            'json': 'json',
            'xml': 'xml',
            'yaml': 'yaml',
            'bash': 'bash',
            'shell': 'bash',
            'sql': 'sql',
            'markdown': 'markdown',
            'latex': 'latex',
            'r': 'r',
            'matlab': 'matlab'
        }
        return language_map.get(language, 'plaintext')

    # Type-based mapping for artifacts without explicit language
    type_map = {
        'code': 'plaintext',
        'document': 'markdown',
        'report': 'markdown',
        'analysis': 'json',
        'data': 'json',
        'diagram': 'plaintext',
        'chart': 'plaintext'
    }

    return type_map.get(art_type, 'plaintext')


def merge_artifacts(existing_artifacts: List[Dict[str, Any]],
                   new_artifacts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Merge two lists of artifacts, avoiding duplicates.

    Args:
        existing_artifacts: Current artifacts
        new_artifacts: New artifacts to add

    Returns:
        Combined list with duplicates removed
    """
    if not existing_artifacts:
        return new_artifacts or []

    if not new_artifacts:
        return existing_artifacts

    # Create a map of existing artifact signatures for duplicate detection
    existing_signatures = set()
    for art in existing_artifacts:
        signature = (art.get('type', ''), art.get('file_name', ''), art.get('language', ''))
        existing_signatures.add(signature)

    # Add new artifacts that don't conflict
    merged = existing_artifacts.copy()

    for new_art in new_artifacts:
        signature = (new_art.get('type', ''), new_art.get('file_name', ''), new_art.get('language', ''))
        if signature not in existing_signatures:
            merged.append(new_art)
            existing_signatures.add(signature)
        else:
            logger.debug(f"Skipping duplicate artifact: {signature}")

    logger.info(f"Merged artifacts: {len(existing_artifacts)} existing + {len(new_artifacts)} new = {len(merged)} total")
    return merged


def export_artifacts_to_files(artifacts: List[Dict[str, Any]],
                            base_path: str) -> List[str]:
    """
    Export artifacts to the filesystem for download/access.

    Args:
        artifacts: List of artifact dictionaries
        base_path: Base directory path for exports

    Returns:
        List of exported file paths
    """
    import os
    from pathlib import Path

    exported_files = []

    if not artifacts:
        return exported_files

    base_dir = Path(base_path)
    base_dir.mkdir(parents=True, exist_ok=True)

    for artifact in artifacts:
        code = artifact.get('code', '')
        file_name = artifact.get('file_name', '')

        if not code or not file_name:
            logger.debug(f"Skipping artifact export - missing code or filename: {artifact.get('type', 'unknown')}")
            continue

        try:
            # Sanitize filename
            safe_filename = "".join(c for c in file_name if c.isalnum() or c in '._-').strip()
            if not safe_filename:
                safe_filename = f"artifact_{id(artifact)}.txt"

            file_path = base_dir / safe_filename

            # Write file
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(code)

            exported_files.append(str(file_path))
            logger.debug(f"Exported artifact to: {file_path}")

        except Exception as e:
            logger.error(f"Failed to export artifact {file_name}: {e}")

    logger.info(f"Exported {len(exported_files)} artifacts to {base_path}")
    return exported_files
