# system_config.toml
# Contains settings that apply to the entire application for ALL users.

[SYSTEM]
# RAG_TYPES moved to settings.<USER>.toml
GENERATE_METHODS = [ "EasyOCR", "LlamaParse", "NvidiaAI", "GeminiAI" ]
AVAILABLE_THEMES = [
    "light_classic",  "light_modern",
    "dark_classic",   "dark_modern",
    "green_classic",  "green_modern",
    "blue_classic",   "blue_modern",
    "purple_classic", "purple_modern"
]

[LOGGING]
# Global logging level configuration for the entire application
# Python logging levels: CRITICAL=50, ERROR=40, WARNING=30, INFO=20, DEBUG=10
LEVEL = 20  # INFO level (shows messages of sufficient alerting level)
WEBSOCKET_LOG = true
GENERATION_LOG = true
API_LOG = false  # Disable verbose HTTP middleware logs
CACHE_LOG = false

# Colorful logging configuration
COLORS_ENABLED = true  # Enable/disable ANSI color codes in logs
COLOR_SCHEME = "uvicorn"  # Color scheme: "uvicorn", "dark", "light"

# Component-specific logging levels (overrides global LEVEL for noisy components)
[LOGGING.COMPONENT_LEVELS]
# UNIFIED LOGGING SYSTEM - Complete replacement of legacy uvicorn loggers
"sss.main" = 20                 # main application
"sss.config" = 20               # configuration
"sss.shared" = 20               # shared utilities
"sss.gen_index" = 20            # Generate RAG indexing utilities
"sss.gen_prog" = 20             # Generate progress tracking
"sss.gen_ocr" = 20              # Generate OCR reader
"sss.gen_manager" = 20          # Generate Manager MVC-Model
"sss.gen_event" = 20            # Generate Event System
"sss.gen_session" = 20          # Generate RAG Session Manager
"sss.workflow" = 20             # workflow adapters porting
"sss.history" = 20              # chat history
"sss.dto" = 20                  # DTO Status Data
"sss.test" = 20                 # tests

# EXTERNAL LIBRARY LOGGING CONTROL - Suppress noisy third-party libraries
"httpx" = 20                    # HTTP client library
"urllib3" = 20                  # URL handling
"requests" = 20                 # HTTP requests
"PIL" = 20                      # Pillow/PIL image library
"llama_index" = 20              # LlamaIndex core
"llama_parse" = 20              # LlamaParse
"openai" = 20                   # OpenAI client
"asyncio" = 20                  # asyncio
"concurrent" = 20               # concurrent.futures

#  UVICORN HTTP ACCESS LOGGING CONTROL
"uvicorn" = 20                  # uvicorn logs
"uvicorn.access" = 30           # Disable uvicorn HTTP access logs
# "uvicorn.error" = 50          # Uncomment to disable error logs too

[CHATBOT_SERVER]
# Settings for the main, single server instance
PROTOCOL = "HTTP"
PORT = 8000
SSL_CERT_PATH = ""
SSL_KEY_PATH = ""

[GENERATE_AI_METHOD]
NvidiaAI_SELECTED_MODEL = "microsoft/phi-4-multimodal-instruct"
GeminiAI_SELECTED_MODEL = "gemini-2.0-flash"

[MODEL_PARAMETERS]
AI_PARSER_PARAMS = { }     # { temperature = 0.2, top_p = 0.5 }
CHATBOT_LLM_PARAMS = { temperature = 0.2, top_p = 0.7 }

[AI_MODELS_AVAILABLE]
# Full list of AI models the administrator has made available in the system.
# These are specifically for methods that leverage AI models.
AI_PARSERS = [
    { GEN_METHOD = "GeminiAI", ID = "gemini-1.5-flash" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.0-flash-lite" },

    { GEN_METHOD = "NvidiaAI", ID = "microsoft/phi-4-multimodal-instruct" },
    { GEN_METHOD = "NvidiaAI", ID = "google/gemma-3n-e4b-it" },
]

CHATBOT = [
    { PROVIDER = "OpenAI",       ID = "gpt-4o" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.5-flash" },
    { PROVIDER = "azureAI",      ID = "deepseek/DeepSeek-R1" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-4" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-5" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-4.1" },
    { PROVIDER = "azureAI",      ID = "xai/grok-3" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-r1-distill-llama-70b" },
    { PROVIDER = "OpenRouter",   ID = "openai/gpt-4.1" },
    { PROVIDER = "OpenRouter",   ID = "x-ai/grok-3" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.1-405b-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.1-70b-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.3-70b-instruct" },
    { PROVIDER = "nvidia",       ID = "openai/gpt-oss-120b" },
    { PROVIDER = "bernard",      ID = "bern-smart" }
]
