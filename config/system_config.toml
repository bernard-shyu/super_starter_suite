# system_config.toml
# Contains settings that apply to the entire application for ALL users.

[SYSTEM]
# RAG_TYPES moved to settings.<USER>.toml
GENERATE_METHODS = [ "EasyOCR", "LlamaParse", "NvidiaAI", "GeminiAI" ]
AVAILABLE_THEMES = [
    "light_classic",  "light_modern",
    "dark_classic",   "dark_modern",
    "green_classic",  "green_modern",
    "blue_classic",   "blue_modern",
    "purple_classic", "purple_modern"
]

[LOGGING]
# Global logging level configuration for the entire application
# Python logging levels: CRITICAL=50, ERROR=40, WARNING=30, INFO=20, DEBUG=10
LEVEL = 20  # INFO level (shows messages of sufficient alerting level)
WEBSOCKET_LOG = true
GENERATION_LOG = true
API_LOG = false  # Disable verbose HTTP middleware logs
CACHE_LOG = false
EXTERNAL_HTTP_LOG = false  # Disable noisy external HTTP request logs (httpx, requests, urllib3)

# Colorful logging configuration
COLORS_ENABLED = true  # Enable/disable ANSI color codes in logs
COLOR_SCHEME = "uvicorn"  # Color scheme: "uvicorn", "dark", "light"

# Component-specific logging levels (overrides global LEVEL for noisy components)
[LOGGING.COMPONENT_LEVELS]
# UNIFIED LOGGING SYSTEM - Complete replacement of legacy uvicorn loggers
"sss.main" = 20                 # main application
"sss.config" = 20               # configuration
"sss.shared" = 20               # shared utilities
"sss.gen_index" = 20            # Generate RAG indexing utilities
"sss.gen_prog" = 20             # Generate progress tracking
"sss.gen_ocr" = 20              # Generate OCR reader
"sss.gen_event" = 20            # Generate Event System
"sss.gen_session" = 20          # Generate RAG Session Manager
"sss.history" = 20              # chat history
"sss.history.lifecycle" = 20    # session lifecycle operations
"sss.history.storage" = 20      # core history persistence
"sss.endpoints" = 20            # FastAPI endpoint decorators
"sss.sess_manager" = 20         # session management - DEBUG level for context persistence issues
"sss.dto" = 20                  # DTO Status Data
"sss.test" = 20                 # tests

# UNIFIED WORKFLOW EXECUTION SYSTEM - New centralized execution architecture
"sss.workflow.loader" = 20             # workflow module loading system - DEBUG level for configuration issues
"sss.workflow.ui_event" = 20           # workflow UI / Event - INFO level
"sss.workflow.utils" = 20              # workflow utilities - INFO level
"sss.workflow.executor" = 10           # unified workflow executor service - DEBUG level for execution tracing

# WORKFLOW LOGGERS - All workflows (adapted and ported) use consistent naming
"sss.workflow.adapted" = 10            # Adapted workflows
"sss.workflow.ported" = 10             # Ported workflows 
"sss.workflow.meta" = 10               # Meta/General workflows

# EXTERNAL LIBRARY LOGGING CONTROL - Suppress noisy third-party libraries
"httpx" = 30                    # HTTP client library
"urllib3" = 30                  # URL handling
"requests" = 30                 # HTTP requests
"PIL" = 20                      # Pillow/PIL image library
"llama_index" = 20              # LlamaIndex core
"llama_parse" = 20              # LlamaParse
"openai" = 20                   # OpenAI client
"asyncio" = 20                  # asyncio
"concurrent" = 20               # concurrent.futures

#  UVICORN HTTP ACCESS LOGGING CONTROL
"uvicorn" = 20                  # uvicorn logs
"uvicorn.access" = 30           # Disable uvicorn HTTP access logs
# "uvicorn.error" = 50          # Uncomment to disable error logs too

[CHATBOT_SERVER]
# Settings for the main, single server instance
PROTOCOL = "HTTP"
PORT = 8000
SSL_CERT_PATH = ""
SSL_KEY_PATH = ""

[GENERATE_AI_METHOD]
NvidiaAI_SELECTED_MODEL = "microsoft/phi-4-multimodal-instruct"
GeminiAI_SELECTED_MODEL = "gemini-2.0-flash"

[MODEL_PARAMETERS]
AI_PARSER_PARAMS = { }     # { temperature = 0.2, top_p = 0.5 }
CHATBOT_LLM_PARAMS = { temperature = 0.2, top_p = 0.7 }

[AI_MODELS_AVAILABLE]
# Full list of AI models the administrator has made available in the system.
# These are specifically for methods that leverage AI models.
AI_PARSERS = [
    { GEN_METHOD = "GeminiAI", ID = "gemini-1.5-flash" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.0-flash" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.0-flash-lite" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.5-flash" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.5-flash-lite" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-2.5-pro" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-3.0-flash" },
    { GEN_METHOD = "GeminiAI", ID = "gemini-3.0-pro" },

    { GEN_METHOD = "NvidiaAI", ID = "microsoft/phi-4-multimodal-instruct" },
    { GEN_METHOD = "NvidiaAI", ID = "microsoft/phi-3.5-vision-instruct" },
    { GEN_METHOD = "NvidiaAI", ID = "mistralai/mistral-small-3.1-24b-instruct-2503" },
    { GEN_METHOD = "NvidiaAI", ID = "meta/llama-4-scout-17b-16e-instruct" },
    { GEN_METHOD = "NvidiaAI", ID = "meta/llama-4-maverick-17b-128e-instruct" },
    { GEN_METHOD = "NvidiaAI", ID = "nvidia/llama-3.1-nemotron-nano-vl-8b-v1" },
    { GEN_METHOD = "NvidiaAI", ID = "google/gemma-3-27b-it" },
    { GEN_METHOD = "NvidiaAI", ID = "google/gemma-3n-e4b-it" },
    { GEN_METHOD = "NvidiaAI", ID = "google/gemma-3n-e2b-it" },
]

CHATBOT = [
    { PROVIDER = "OpenAI",       ID = "gpt-4o" },
    { PROVIDER = "google_GenAI", ID = "gemini-1.5-flash" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.0-flash-lite" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.0-flash" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.5-flash-lite" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.5-flash" },
    { PROVIDER = "google_GenAI", ID = "gemini-2.5-pro" },
    { PROVIDER = "azureAI",      ID = "ai21-labs/AI21-Jamba-1.5-Large" },
    { PROVIDER = "azureAI",      ID = "cohere/cohere-command-a" },
    { PROVIDER = "azureAI",      ID = "cohere/Cohere-command-r-08-2024" },
    { PROVIDER = "azureAI",      ID = "cohere/Cohere-command-r-plus-08-2024" },
    { PROVIDER = "azureAI",      ID = "deepseek/DeepSeek-R1" },
    { PROVIDER = "azureAI",      ID = "deepseek/DeepSeek-R1-0528" },
    { PROVIDER = "azureAI",      ID = "deepseek/DeepSeek-V3-0324" },
    { PROVIDER = "azureAI",      ID = "microsoft/MAI-DS-R1" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-4" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-4-Reasoning" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-4-multimodal-instruct" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-3.5-vision-instruct" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-3.5-moe-instruct" },
    { PROVIDER = "azureAI",      ID = "microsoft/Phi-3-medium-128k-instruct" },
    { PROVIDER = "azureAI",      ID = "mistral-ai/Codestral-2501" },
    { PROVIDER = "azureAI",      ID = "mistral-ai/Mistral-Large-2411" },
    { PROVIDER = "azureAI",      ID = "mistral-ai/mistral-medium-2505" },
    { PROVIDER = "azureAI",      ID = "meta/Llama-4-Scout-17B-16E-Instruct" },
    { PROVIDER = "azureAI",      ID = "meta/Llama-4-Maverick-17B-128E-Instruct-FP8" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-5-chat" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-5" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-4.1" },
    { PROVIDER = "azureAI",      ID = "openai/gpt-4o" },
    { PROVIDER = "azureAI",      ID = "openai/o3" },
    { PROVIDER = "azureAI",      ID = "openai/o3-mini" },
    { PROVIDER = "azureAI",      ID = "openai/o4-mini" },
    { PROVIDER = "azureAI",      ID = "xai/grok-3" },
    { PROVIDER = "OpenRouter",   ID = "agentica-org/deepcoder-14b-preview:free" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-v3-base:free" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-chat-v3-0324:free" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-r1:free" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-r1-0528:free" },
    { PROVIDER = "OpenRouter",   ID = "deepseek/deepseek-r1-distill-llama-70b" },
    { PROVIDER = "OpenRouter",   ID = "google/gemini-2.0-flash-exp:free" },
    { PROVIDER = "OpenRouter",   ID = "meta-llama/llama-4-scout" },
    { PROVIDER = "OpenRouter",   ID = "meta-llama/llama-4-maverick" },
    { PROVIDER = "OpenRouter",   ID = "openai/gpt-4.1" },
    { PROVIDER = "OpenRouter",   ID = "openai/o3-mini" },
    { PROVIDER = "OpenRouter",   ID = "qwen/qwen3-235b-a22b-07-25" },
    { PROVIDER = "OpenRouter",   ID = "x-ai/grok-3" },
    { PROVIDER = "nvidia",       ID = "deepseek-ai/deepseek-r1-0528" },
    { PROVIDER = "nvidia",       ID = "deepseek-ai/deepseek-v3.1-terminus" },
    { PROVIDER = "nvidia",       ID = "deepseek-ai/deepseek-v3.1" },
    { PROVIDER = "nvidia",       ID = "igenius/colosseum_355b_instruct_16k" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.1-405b-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.1-70b-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-3.3-70b-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-4-maverick-17b-128e-instruct" },
    { PROVIDER = "nvidia",       ID = "meta/llama-4-scout-17b-16e-instruct" },
    { PROVIDER = "nvidia",       ID = "microsoft/phi-4-multimodal-instruct" },
    { PROVIDER = "nvidia",       ID = "microsoft/phi-4-mini-instruct" },
    { PROVIDER = "nvidia",       ID = "mistralai/mistral-large-2-instruct" },
    { PROVIDER = "nvidia",       ID = "mistralai/mistral-medium-3-instruct" },
    { PROVIDER = "nvidia",       ID = "mistralai/mistral-small-3.1-24b-instruct-2503  " },
    { PROVIDER = "nvidia",       ID = "mistralai/magistral-small-2506" },
    { PROVIDER = "nvidia",       ID = "nvidia/llama-3.1-nemotron-ultra-253b-v1" },
    { PROVIDER = "nvidia",       ID = "nvidia/llama-3.3-nemotron-super-49b-v1.5" },
    { PROVIDER = "nvidia",       ID = "nvidia/nemotron-4-340b-instruct" },
    { PROVIDER = "nvidia",       ID = "nvidia/nemotron-4-340b-reward" },
    { PROVIDER = "nvidia",       ID = "openai/gpt-oss-120b" },
    { PROVIDER = "nvidia",       ID = "qwen/qwen3-235b-a22b" },
    { PROVIDER = "nvidia",       ID = "qwen/qwen3-coder-480b-a35b-instruct" },
    { PROVIDER = "nvidia",       ID = "qwen/qwen3-next-80b-a3b-instruct" },
    { PROVIDER = "nvidia",       ID = "qwen/qwen3-next-80b-a3b-thinking" },
    { PROVIDER = "nvidia",       ID = "stockmark/stockmark-2-100b-instruct" },
    { PROVIDER = "nvidia",       ID = "writer/palmyra-creative-122b" },
    { PROVIDER = "nvidia",       ID = "writer/palmyra-fin-70b-32k" },
    { PROVIDER = "bernard",      ID = "bern-smart" }
]

#---------------------------------------------------------------------------------------------
# Pluggable Workflow Configuration Section
# - Defines all available workflows with their metadata and configurations
# - 'icon' field can be smiley, or image path (ex. '/static/icons/agentic.png')
# - integrate_type:
#   * adapted: workflows imported from STARTER_TOOLS, no business logic
#   * ported:  workflows ported (NOT imported) from STARTER_TOOLS, with business logic
#   * meta:    workflows of orchestration/multi-agent/complex beyond adapted/ported
#---------------------------------------------------------------------------------------------
[WORKFLOW]
# üéØ ADAPTED WORKFLOWS - Direct STARTER_TOOLS integration (preserve native behavior)
A_agentic_rag        = { code_path = "workflow_adapters.agentic_rag",        timeout = 120.0, display_name = "Agentic RAG (Adapted)",          icon = "üß†", description = "Intelligent document analysis with autonomous agents",   integrate_type = "adapted", response_format = "json", artifact_enabled = false, synthetic_response = "Analysis completed with {count} insights generated",    ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true }
A_code_generator     = { code_path = "workflow_adapters.code_generator",     timeout = 240.0, display_name = "Code Generator (Adapted)",       icon = "üíª", description = "AI-powered code generation and completion",              integrate_type = "adapted", response_format = "json", artifact_enabled = true,  synthetic_response = "Generated {count} code files",                          ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true }
A_deep_research      = { code_path = "workflow_adapters.deep_research",      timeout = 240.0, display_name = "Deep Research (Adapted)",        icon = "üîç", description = "Comprehensive research and analysis",                    integrate_type = "adapted", response_format = "json", artifact_enabled = true,  synthetic_response = "Completed research analysis with {count} deliverables", ui_component = "MultiStageWorkflowProgress", show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true, force_text_structured_predict = true }
A_document_generator = { code_path = "workflow_adapters.document_generator", timeout = 240.0, display_name = "Document Generator (Adapted)",   icon = "üìÑ", description = "Automated document creation",                            integrate_type = "adapted", response_format = "json", artifact_enabled = true,  synthetic_response = "Created {count} documents",                             ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true }
A_financial_report   = { code_path = "workflow_adapters.financial_report",   timeout = 300.0, display_name = "Financial Report (Adapted)",     icon = "üìä", description = "Financial data analysis and reporting",                  integrate_type = "adapted", response_format = "json", artifact_enabled = true,  synthetic_response = "Generated {count} financial reports",                   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true }
A_human_in_the_loop  = { code_path = "workflow_adapters.human_in_the_loop",  timeout = 120.0, display_name = "Human in the Loop (Adapted)",    icon = "üë•", description = "Interactive workflows with human oversight",             integrate_type = "adapted", response_format = "html", artifact_enabled = false, synthetic_response = "Interactive workflow completed with {count} results",   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "None",  show_followup_questions = true, show_workflow_states = true, hie_enabled = true }
P_agentic_rag        = { code_path = "workflow_porting.agentic_rag",         timeout = 120.0, display_name = "Agentic RAG (Ported)",           icon = "üß†", description = "Intelligent document analysis with autonomous agents",   integrate_type = "ported",  response_format = "json", artifact_enabled = false, synthetic_response = "Analysis completed with {count} insights generated",    ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
P_code_generator     = { code_path = "workflow_porting.code_generator",      timeout = 240.0, display_name = "Code Generator (Ported)",        icon = "üíª", description = "AI-powered code generation and completion",              integrate_type = "ported",  response_format = "json", artifact_enabled = true,  synthetic_response = "Generated {count} code files",                          ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
P_deep_research      = { code_path = "workflow_porting.deep_research",       timeout = 400.0, display_name = "Deep Research (Ported)",         icon = "üîç", description = "Comprehensive research and analysis",                    integrate_type = "ported",  response_format = "json", artifact_enabled = true,  synthetic_response = "Completed research analysis with {count} deliverables", ui_component = "MultiStageWorkflowProgress", show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
P_document_generator = { code_path = "workflow_porting.document_generator",  timeout = 240.0, display_name = "Document Generator (Ported)",    icon = "üìÑ", description = "Automated document creation",                            integrate_type = "ported",  response_format = "json", artifact_enabled = true,  synthetic_response = "Created {count} documents",                             ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
P_financial_report   = { code_path = "workflow_porting.financial_report",    timeout = 300.0, display_name = "Financial Report (Ported)",      icon = "üìä", description = "Financial data analysis and reporting",                  integrate_type = "ported",  response_format = "json", artifact_enabled = true,  synthetic_response = "Generated {count} financial reports",                   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Short", show_followup_questions = true, show_workflow_states = true }
P_human_in_the_loop  = { code_path = "workflow_porting.human_in_the_loop",   timeout = 120.0, display_name = "Human in the Loop (Ported)",     icon = "üë•", description = "Interactive workflows with human oversight",             integrate_type = "ported",  response_format = "html", artifact_enabled = false, synthetic_response = "Interactive workflow completed with {count} results",   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "None",  show_followup_questions = true, show_workflow_states = true, hie_enabled = true }
M_rag_codegen       = { code_path = "workflow_meta.M_rag_codegen",         timeout = 600.0, display_name = "RAG + CodeGen (Meta)",           icon = "üîó", description = "Multi-agent pipeline: RAG and Code Generation",          integrate_type = "meta",    response_format = "json", artifact_enabled = true,  synthetic_response = "Multi-agent pipeline completed with {count} outputs",   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
M_rag_docgen        = { code_path = "workflow_meta.M_rag_docgen",          timeout = 600.0, display_name = "RAG + DocGen (Meta)",            icon = "üìÑ", description = "Multi-agent pipeline: RAG and Document Generation",      integrate_type = "meta",    response_format = "json", artifact_enabled = true,  synthetic_response = "Multi-agent pipeline completed with {count} outputs",   ui_component = "SimpleWorkflowProgress",     show_tool_calls = true,  show_citation = "Full",  show_followup_questions = true, show_workflow_states = true }
